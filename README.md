# Cochranâ€™s Theorem â€” Proof and Geometric Interpretation

## ðŸ“Œ Overview

This repository contains a self-contained proof of **Cochranâ€™s theorem**, with an emphasis on the **geometric and statistical interpretation** of quadratic forms, orthogonal projections, and degrees of freedom.

The objective is not only to present the classical result, but also to clarify the deep connection between **linear algebra and statistics**, particularly in the context of **one-way ANOVA**.

---

## ðŸŽ¯ Objectives

- Provide a rigorous proof of Cochranâ€™s theorem  
- Explain the role of:
  - symmetric idempotent matrices  
  - orthogonal projections  
  - quadratic forms of Gaussian vectors  
- Give a geometric intuition for:
  - independence of sums of squares  
  - degrees of freedom  
- Highlight the link with one-way ANOVA  

---

## ðŸ“ Mathematical Setting

Let  

Z ~ Nâ‚™(0, ÏƒÂ² Iâ‚™)

Let Aâ‚, â€¦, Aâ‚› be symmetric idempotent matrices such that:

âˆ‘â‚– Aâ‚– = Iâ‚™  
Aâ‚– Aâ‚— = 0  for k â‰  l  

Define the quadratic forms:

Qâ‚– = Záµ€ Aâ‚– Z  

Cochranâ€™s theorem characterizes the **distribution, independence, and degrees of freedom** of these quadratic forms.

---

## ðŸ§  Key Ideas

- Quadratic forms arise as **squared norms of projections** of a Gaussian vector  
- Orthogonality of subspaces explains **independence**  
- Degrees of freedom correspond to the **dimension (rank)** of each projection  
- The total sum of squares decomposes into orthogonal components  

Geometrically:

> The data vector lives in an n-dimensional space, and Cochranâ€™s theorem decomposes it into orthogonal subspaces; each quadratic form measures the squared length of the projection onto one subspace.

---

## ðŸ“Š Link with ANOVA

Cochranâ€™s theorem provides the theoretical foundation of **one-way ANOVA** by explaining:

- why sums of squares are independent  
- why they follow chi-squared distributions  
- why their degrees of freedom add up correctly  
- why the F-statistic follows an F distribution  


